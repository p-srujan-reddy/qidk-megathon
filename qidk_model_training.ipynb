{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZqTHjbOK3lJ",
        "outputId": "8e3a9aa6-62f6-4db3-d405-ff10e95af9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# prompt: write the code to mount the drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IinZDI3RVSCk",
        "outputId": "ebe116e9-1b41-40b6-af5b-f03f5a58232a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.10/dist-packages (1.13.0)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tf2onnx) (2.0.7)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tf2onnx) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install tf2onnx onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "L4Aw-H3lLBMx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2, VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def ensure_directories():\n",
        "    \"\"\"Create necessary directories for model checkpoints and outputs\"\"\"\n",
        "    directories = ['checkpoints', 'models', 'plots']\n",
        "    for directory in directories:\n",
        "        os.makedirs(directory, exist_ok=True)\n",
        "    return directories\n",
        "\n",
        "def split_dataset(base_dir, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15):\n",
        "    \"\"\"\n",
        "    Split dataset into train, validation, and test sets\n",
        "    \"\"\"\n",
        "    # Create output directories\n",
        "    splits = ['train', 'validation', 'test']\n",
        "    for split in splits:\n",
        "        split_dir = os.path.join(output_dir, split)\n",
        "        if os.path.exists(split_dir):\n",
        "            shutil.rmtree(split_dir)\n",
        "        os.makedirs(split_dir)\n",
        "\n",
        "    # Process each class\n",
        "    class_names = []\n",
        "    for class_folder in os.listdir(base_dir):\n",
        "        class_path = os.path.join(base_dir, class_folder)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "\n",
        "        class_names.append(class_folder)\n",
        "\n",
        "        # Get all images in the class\n",
        "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        # Shuffle images\n",
        "        np.random.shuffle(images)\n",
        "\n",
        "        # Calculate split indices\n",
        "        n_images = len(images)\n",
        "        n_train = int(train_ratio * n_images)\n",
        "        n_val = int(val_ratio * n_images)\n",
        "\n",
        "        # Split images\n",
        "        train_images = images[:n_train]\n",
        "        val_images = images[n_train:n_train + n_val]\n",
        "        test_images = images[n_train + n_val:]\n",
        "\n",
        "        # Copy images to respective directories\n",
        "        for split, split_images in zip(splits, [train_images, val_images, test_images]):\n",
        "            split_class_dir = os.path.join(output_dir, split, class_folder)\n",
        "            os.makedirs(split_class_dir, exist_ok=True)\n",
        "\n",
        "            for img in split_images:\n",
        "                src = os.path.join(class_path, img)\n",
        "                dst = os.path.join(split_class_dir, img)\n",
        "                shutil.copy2(src, dst)\n",
        "\n",
        "        print(f\"Processed {class_folder}: {len(train_images)} train, {len(val_images)} validation, {len(test_images)} test\")\n",
        "\n",
        "    return class_names\n",
        "\n",
        "def create_data_generators(data_dir, img_height=224, img_width=224, batch_size=32):\n",
        "    \"\"\"\n",
        "    Create data generators for train, validation, and test sets with augmentation\n",
        "    \"\"\"\n",
        "    # Training data generator with augmentation\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Validation and test data generators (only rescaling)\n",
        "    valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Create generators\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        os.path.join(data_dir, 'train'),\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    validation_generator = valid_test_datagen.flow_from_directory(\n",
        "        os.path.join(data_dir, 'validation'),\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    test_generator = valid_test_datagen.flow_from_directory(\n",
        "        os.path.join(data_dir, 'test'),\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_generator, validation_generator, test_generator\n",
        "\n",
        "\n",
        "\n",
        "def create_basic_cnn(input_shape, num_classes):\n",
        "    \"\"\"Create a basic 3-layer CNN\"\"\"\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(2, 2),\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def create_vgg_net(input_shape, num_classes):\n",
        "    \"\"\"Create VGG16-based model\"\"\"\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def create_mobilenet(input_shape, num_classes):\n",
        "    \"\"\"Create MobileNetV2-based model\"\"\"\n",
        "    # Load MobileNetV2 with pretrained ImageNet weights and without the top classifier\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze the base model to prevent its weights from being updated\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Build the full model\n",
        "    model = Sequential([\n",
        "        base_model,  # Output shape: (None, 7, 7, 1280)\n",
        "        GlobalAveragePooling2D(),  # Converts to (None, 1280)\n",
        "        Dense(128, activation='relu'),  # Hidden layer\n",
        "        Dropout(0.5),  # Regularization\n",
        "        Dense(num_classes, activation='softmax')  # Output layer for classification\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_model(model, train_generator, validation_generator, test_generator, model_name, epochs=50):\n",
        "    \"\"\"\n",
        "    Train and evaluate a model with early stopping and learning rate reduction\n",
        "    \"\"\"\n",
        "    # Define callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=8,\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=5,\n",
        "            min_lr=1e-6\n",
        "        ),\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=f'/content/drive/MyDrive/qidk/checkpoints/{model_name}_best.keras',  # Updated extension to .keras\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            mode='max'\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_results = model.evaluate(test_generator, verbose=1)\n",
        "    print(f\"\\nTest results for {model_name}:\")\n",
        "    print(f\"Test Loss: {test_results[0]:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
        "\n",
        "    return history, test_results\n",
        "\n",
        "def plot_training_history(history, model_name):\n",
        "    \"\"\"Plot and save training history\"\"\"\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "    plt.title(f'{model_name} Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training')\n",
        "    plt.plot(history.history['val_loss'], label='Validation')\n",
        "    plt.title(f'{model_name} Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'plots/{model_name}_history.png')\n",
        "    plt.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npIaPTenfA0a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIWaaogRNeUZ",
        "outputId": "985bbcdc-31df-4028-ef50-f76e052725dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Splitting dataset...\n",
            "Processed utkatasana_output: 49 train, 10 validation, 12 test\n",
            "Processed vrikshasana_output: 37 train, 8 validation, 9 test\n",
            "Processed natrajasana_output: 49 train, 10 validation, 12 test\n",
            "\n",
            "Creating data generators...\n",
            "Found 135 images belonging to 3 classes.\n",
            "Found 28 images belonging to 3 classes.\n",
            "Found 33 images belonging to 3 classes.\n",
            "\n",
            "Training mobile_net...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 941ms/step - accuracy: 0.4020 - loss: 1.4160 - val_accuracy: 0.5714 - val_loss: 0.6538 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - accuracy: 0.6503 - loss: 0.7439 - val_accuracy: 0.8929 - val_loss: 0.4870 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.7896 - loss: 0.4698 - val_accuracy: 0.8929 - val_loss: 0.2491 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - accuracy: 0.8559 - loss: 0.3708 - val_accuracy: 0.9286 - val_loss: 0.2514 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.9047 - loss: 0.2626 - val_accuracy: 0.9286 - val_loss: 0.1737 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.8709 - loss: 0.2790 - val_accuracy: 0.9286 - val_loss: 0.1961 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - accuracy: 0.9417 - loss: 0.1876 - val_accuracy: 0.9286 - val_loss: 0.1778 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - accuracy: 0.8906 - loss: 0.2963 - val_accuracy: 0.9643 - val_loss: 0.1720 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.9163 - loss: 0.2076 - val_accuracy: 0.9643 - val_loss: 0.1680 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.8996 - loss: 0.2360 - val_accuracy: 0.9643 - val_loss: 0.1445 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.9447 - loss: 0.1493 - val_accuracy: 0.9286 - val_loss: 0.1640 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.9184 - loss: 0.1522 - val_accuracy: 0.9643 - val_loss: 0.1067 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9394 - loss: 0.1931 - val_accuracy: 0.9286 - val_loss: 0.1800 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9705 - loss: 0.0835 - val_accuracy: 0.9643 - val_loss: 0.1548 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9946 - loss: 0.0614 - val_accuracy: 0.9643 - val_loss: 0.1407 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.9498 - loss: 0.1415 - val_accuracy: 0.9643 - val_loss: 0.0916 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9836 - loss: 0.0821 - val_accuracy: 0.9643 - val_loss: 0.1459 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9932 - loss: 0.0437 - val_accuracy: 0.9643 - val_loss: 0.1178 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.9622 - loss: 0.0990 - val_accuracy: 0.9643 - val_loss: 0.0796 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.9701 - loss: 0.1454 - val_accuracy: 0.9643 - val_loss: 0.1257 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9977 - loss: 0.0452 - val_accuracy: 0.9643 - val_loss: 0.1706 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.9515 - loss: 0.0886 - val_accuracy: 0.9643 - val_loss: 0.1408 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9854 - loss: 0.0396 - val_accuracy: 0.9643 - val_loss: 0.1792 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.9785 - loss: 0.0625 - val_accuracy: 0.9643 - val_loss: 0.1898 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.9956 - loss: 0.0596 - val_accuracy: 0.9643 - val_loss: 0.1938 - learning_rate: 2.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.9977 - loss: 0.0360 - val_accuracy: 0.9643 - val_loss: 0.1879 - learning_rate: 2.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9967 - loss: 0.0276 - val_accuracy: 0.9643 - val_loss: 0.1827 - learning_rate: 2.0000e-04\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 672ms/step - accuracy: 1.0000 - loss: 0.0581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test results for mobile_net:\n",
            "Test Loss: 0.0491\n",
            "Test Accuracy: 1.0000\n",
            "\n",
            "Training complete! Check the 'plots' directory for training history visualization.\n"
          ]
        }
      ],
      "source": [
        "# Set parameters\n",
        "BASE_DIR = '/content/drive/MyDrive/qidk/dataset_image_with_pose'  # Replace with your dataset path\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/qidk/processed_dataset'\n",
        "IMG_HEIGHT = 224\n",
        "IMG_WIDTH = 224\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# Create necessary directories\n",
        "ensure_directories()\n",
        "os.makedirs('/content/drive/MyDrive/qidk/checkpoints/', exist_ok=True)\n",
        "# Split dataset\n",
        "print(\"Splitting dataset...\")\n",
        "class_names = split_dataset(BASE_DIR, OUTPUT_DIR)\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Create data generators\n",
        "print(\"\\nCreating data generators...\")\n",
        "train_generator, validation_generator, test_generator = create_data_generators(\n",
        "    OUTPUT_DIR,\n",
        "    IMG_HEIGHT,\n",
        "    IMG_WIDTH,\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "input_shape = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "models = {\n",
        "    # 'basic_cnn': create_basic_cnn(input_shape, num_classes),\n",
        "    # 'vgg_net': create_vgg_net(input_shape, num_classes),\n",
        "    'mobile_net': create_mobilenet(input_shape, num_classes)\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "histories = {}\n",
        "test_results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    history, test_result = train_and_evaluate_model(\n",
        "        model,\n",
        "        train_generator,\n",
        "        validation_generator,\n",
        "        test_generator,\n",
        "        model_name\n",
        "    )\n",
        "\n",
        "    histories[model_name] = history\n",
        "    test_results[model_name] = test_result\n",
        "\n",
        "    os.makedirs('/content/drive/MyDrive/qidk/models', exist_ok=True)\n",
        "\n",
        "    # Save model\n",
        "    model.save(f'/content/drive/MyDrive/qidk/models/{model_name}_final.keras', save_format='keras')\n",
        "\n",
        "\n",
        "print(\"\\nTraining complete! Check the 'plots' directory for training history visualization.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "oorIzOUlt2DE",
        "outputId": "2e861a4a-8797-4fc8-e05d-050a94ba20d3"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Layer \"dense_6\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2589>, <KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2590>]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-04473bdf27ce>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Convert the MobileNet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mconvert_to_tflite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/qidk/models/mobile_net_final.keras'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/qidk/tflite_models/mobile_net.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-04473bdf27ce>\u001b[0m in \u001b[0;36mconvert_to_tflite\u001b[0;34m(model_path, output_path, quantize)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tflite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load the Keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Create a TFLite converter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_zip\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_keras_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         return saving_lib.load_model(\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    235\u001b[0m             )\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             return _load_model_from_fileobj(\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mconfig_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         model = _model_from_config(\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mconfig_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;31m# Construct the model from the configuration file in the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mObjectSharingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         model = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcustom_obj_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 )\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         if (\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_rebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m_maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_lock_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36mbuild_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0moriginal_build_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0;31m# Record build config.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_build_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;31m# Can happen if shape inference is not implemented.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;34mf'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;34mf\" but it received {len(inputs)} input tensors. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer \"dense_6\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2589>, <KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2590>]"
          ]
        }
      ],
      "source": [
        "def convert_to_tflite(model_path, output_path, quantize=True):\n",
        "    # Load the Keras model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Create a TFLite converter\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "    if quantize:\n",
        "        # Apply dynamic range quantization\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "    # Convert the model\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the TFLite model\n",
        "    with open(output_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(f'TFLite model saved to: {output_path}')\n",
        "\n",
        "# Convert the MobileNet model\n",
        "convert_to_tflite('/content/drive/MyDrive/qidk/models/mobile_net_final.keras', '/content/drive/MyDrive/qidk/tflite_models/mobile_net.tflite')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "GXIhdZz7lzQ4",
        "outputId": "f7c9dcac-1e59-4d87-dd9f-978e31eeac33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Converting basic_cnn...\n",
            "Model /content/drive/MyDrive/qidk/models/basic_cnn_final.keras not found\n",
            "\n",
            "Converting vgg_net...\n",
            "Model /content/drive/MyDrive/qidk/models/vgg_net_final.keras not found\n",
            "\n",
            "Converting mobile_net...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Layer \"dense_6\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2266>, <KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2267>]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6c2602a758b7>\u001b[0m in \u001b[0;36m<cell line: 96>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Convert all models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mconvert_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFLITE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-6c2602a758b7>\u001b[0m in \u001b[0;36mconvert_all_models\u001b[0;34m(model_dir, output_dir, class_names)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# Convert model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_model_to_tflite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtflite_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;31m# Generate and save metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-6c2602a758b7>\u001b[0m in \u001b[0;36mconvert_model_to_tflite\u001b[0;34m(model_path, output_path, quantize)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Create TFLite converter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_zip\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_keras_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         return saving_lib.load_model(\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    235\u001b[0m             )\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             return _load_model_from_fileobj(\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mconfig_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         model = _model_from_config(\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mconfig_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py\u001b[0m in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;31m# Construct the model from the configuration file in the archive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mObjectSharingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         model = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcustom_obj_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    349\u001b[0m                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 )\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         if (\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrebuild\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_rebuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36m_maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_lock_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36mbuild_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0moriginal_build_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0;31m# Record build config.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_build_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;31m# Can happen if shape inference is not implemented.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;34mf'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;34mf\" but it received {len(inputs)} input tensors. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Layer \"dense_6\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2266>, <KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_2267>]"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def convert_model_to_tflite(model_path, output_path, quantize=True):\n",
        "    \"\"\"\n",
        "    Convert Keras model to TFLite format with optional quantization\n",
        "\n",
        "    Args:\n",
        "        model_path: Path to the saved Keras model\n",
        "        output_path: Path where to save the TFLite model\n",
        "        quantize: Whether to apply post-training quantization\n",
        "    \"\"\"\n",
        "    # Load the model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Create TFLite converter\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "    if quantize:\n",
        "        # Apply post-training dynamic range quantization\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        # Optionally add more quantization configurations:\n",
        "        # converter.target_spec.supported_types = [tf.float16]\n",
        "        # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "    # Convert the model\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the TFLite model\n",
        "    with open(output_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    # Get model size\n",
        "    model_size = os.path.getsize(output_path) / (1024 * 1024)  # Size in MB\n",
        "    print(f\"Model saved to {output_path}\")\n",
        "    print(f\"Model size: {model_size:.2f} MB\")\n",
        "\n",
        "    return tflite_model\n",
        "\n",
        "def generate_metadata(model_name, class_names):\n",
        "    \"\"\"\n",
        "    Generate metadata for the TFLite model\n",
        "\n",
        "    Args:\n",
        "        model_name: Name of the model\n",
        "        class_names: List of class names\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"name\": model_name,\n",
        "        \"description\": \"Image classification model for pose detection\",\n",
        "        \"version\": \"1.0\",\n",
        "        \"author\": \"Your Name\",\n",
        "        \"license\": \"Apache License 2.0\",\n",
        "        \"input_shape\": [224, 224, 3],\n",
        "        \"input_dtype\": \"float32\",\n",
        "        \"classes\": class_names\n",
        "    }\n",
        "\n",
        "def convert_all_models(model_dir, output_dir, class_names):\n",
        "    \"\"\"\n",
        "    Convert all models in the directory to TFLite format\n",
        "\n",
        "    Args:\n",
        "        model_dir: Directory containing Keras models\n",
        "        output_dir: Directory to save TFLite models\n",
        "        class_names: List of class names\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Convert each model\n",
        "    for model_name in ['basic_cnn', 'vgg_net', 'mobile_net']:\n",
        "        print(f\"\\nConverting {model_name}...\")\n",
        "\n",
        "        # Paths\n",
        "        keras_path = os.path.join(model_dir, f'{model_name}_final.keras')\n",
        "        tflite_path = os.path.join(output_dir, f'{model_name}.tflite')\n",
        "\n",
        "        # Convert model\n",
        "        if os.path.exists(keras_path):\n",
        "            tflite_model = convert_model_to_tflite(keras_path, tflite_path)\n",
        "\n",
        "            # Generate and save metadata\n",
        "            metadata = generate_metadata(model_name, class_names)\n",
        "            metadata_path = os.path.join(output_dir, f'{model_name}_metadata.json')\n",
        "\n",
        "            with open(metadata_path, 'w') as f:\n",
        "                import json\n",
        "                json.dump(metadata, f, indent=2)\n",
        "\n",
        "            print(f\"Metadata saved to {metadata_path}\")\n",
        "        else:\n",
        "            print(f\"Model {keras_path} not found\")\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_DIR = '/content/drive/MyDrive/qidk/models'\n",
        "    TFLITE_DIR = '/content/drive/MyDrive/qidk/tflite_models'\n",
        "\n",
        "    # Convert all models\n",
        "    convert_all_models(MODEL_DIR, TFLITE_DIR, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uih0RpelzOB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIlzOc05lzK8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptaKFNtIfBu-",
        "outputId": "0dcfd0f7-84b6-45de-b0f1-892022ee3d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 135 images belonging to 3 classes.\n",
            "\n",
            "Processing basic_cnn_final\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmp6te5ug2v'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  133503359040176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133502618264400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133503377159120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133503377153664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133502616982224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133502616986096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133502616990320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133502616981168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133502616699120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  133502616712320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/convert.py:983: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "ERROR:__main__:Error converting to ONNX: 'FuncGraph' object has no attribute '_captures'\n",
            "ERROR:root:Error processing model /content/models/basic_cnn_final.h5: 'FuncGraph' object has no attribute '_captures'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing vgg_net_final\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Error converting to TFLite: Layer \"dense_24\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 512), dtype=float32, sparse=False, name=keras_tensor_1068>, <KerasTensor shape=(None, 7, 7, 512), dtype=float32, sparse=False, name=keras_tensor_1069>]\n",
            "ERROR:root:Error processing model /content/models/vgg_net_final.h5: Layer \"dense_24\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 512), dtype=float32, sparse=False, name=keras_tensor_1068>, <KerasTensor shape=(None, 7, 7, 512), dtype=float32, sparse=False, name=keras_tensor_1069>]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing mobile_net_final\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Error converting to TFLite: Layer \"dense_26\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_1391>, <KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_1392>]\n",
            "ERROR:root:Error processing model /content/models/mobile_net_final.h5: Layer \"dense_26\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_1391>, <KerasTensor shape=(None, 7, 7, 1280), dtype=float32, sparse=False, name=keras_tensor_1392>]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tf2onnx\n",
        "import os\n",
        "import logging\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "class ModelConverter:\n",
        "    def __init__(self, input_shape=(224, 224, 3), output_dir='converted_models'):\n",
        "        self.input_shape = input_shape\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        logging.basicConfig(level=logging.INFO)\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def create_representative_dataset(self, train_generator):\n",
        "        \"\"\"Create a representative dataset for quantization\"\"\"\n",
        "        def representative_dataset():\n",
        "            for _ in range(100):\n",
        "                batch = next(train_generator)[0]\n",
        "                # Normalize the batch if not already done\n",
        "                if batch.max() > 1:\n",
        "                    batch = batch / 255.0\n",
        "                yield [batch.astype(np.float32)]\n",
        "        return representative_dataset\n",
        "\n",
        "    def fix_sequential_model(self, model_path):\n",
        "        \"\"\"Fix Sequential model for ONNX conversion\"\"\"\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "        inputs = tf.keras.Input(shape=self.input_shape, name='input')\n",
        "        x = inputs\n",
        "        for layer in model.layers:\n",
        "            x = layer(x)\n",
        "        fixed_model = tf.keras.Model(inputs=inputs, outputs=x, name='fixed_model')\n",
        "        return fixed_model\n",
        "\n",
        "    def fix_transfer_learning_model(self, model_path):\n",
        "        \"\"\"Fix transfer learning models (VGG, MobileNet)\"\"\"\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "        # Get the base model layers\n",
        "        base_model = None\n",
        "        if 'vgg_net' in str(model_path):\n",
        "            base_model = tf.keras.applications.VGG16(\n",
        "                weights='imagenet',\n",
        "                include_top=False,\n",
        "                input_shape=self.input_shape\n",
        "            )\n",
        "        elif 'mobile_net' in str(model_path):\n",
        "            base_model = tf.keras.applications.MobileNetV2(\n",
        "                weights='imagenet',\n",
        "                include_top=False,\n",
        "                input_shape=self.input_shape\n",
        "            )\n",
        "\n",
        "        base_model.trainable = False\n",
        "\n",
        "        # Create new model with fixed architecture\n",
        "        inputs = tf.keras.Input(shape=self.input_shape, name='input')\n",
        "        x = base_model(inputs)\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "        x = tf.keras.layers.Dropout(0.5)(x)\n",
        "        outputs = tf.keras.layers.Dense(model.outputs[0].shape[-1], activation='softmax')(x)\n",
        "\n",
        "        fixed_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        # Copy weights from the original model's dense layers\n",
        "        orig_dense_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Dense)]\n",
        "        new_dense_layers = [layer for layer in fixed_model.layers if isinstance(layer, tf.keras.layers.Dense)]\n",
        "\n",
        "        for orig_layer, new_layer in zip(orig_dense_layers, new_dense_layers):\n",
        "            new_layer.set_weights(orig_layer.get_weights())\n",
        "\n",
        "        return fixed_model\n",
        "\n",
        "    def convert_to_tflite(self, model_path, train_generator=None, quantize=True):\n",
        "        \"\"\"Convert model to TFLite format\"\"\"\n",
        "        try:\n",
        "            # Fix model architecture based on type\n",
        "            if 'vgg_net' in str(model_path) or 'mobile_net' in str(model_path):\n",
        "                model = self.fix_transfer_learning_model(model_path)\n",
        "            else:\n",
        "                model = self.fix_sequential_model(model_path)\n",
        "\n",
        "            converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "            if quantize:\n",
        "                converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "                if train_generator is not None:\n",
        "                    converter.representative_dataset = self.create_representative_dataset(train_generator)\n",
        "                    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "                    converter.inference_input_type = tf.uint8\n",
        "                    converter.inference_output_type = tf.uint8\n",
        "                else:\n",
        "                    converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "            tflite_model = converter.convert()\n",
        "\n",
        "            model_name = Path(model_path).stem\n",
        "            quant_type = 'int8' if train_generator else 'float16'\n",
        "            tflite_path = self.output_dir / f\"{model_name}_{quant_type}.tflite\"\n",
        "\n",
        "            with open(tflite_path, 'wb') as f:\n",
        "                f.write(tflite_model)\n",
        "\n",
        "            self.logger.info(f\"Successfully converted model to TFLite: {tflite_path}\")\n",
        "            return tflite_path\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error converting to TFLite: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def convert_to_onnx(self, model_path):\n",
        "        \"\"\"Convert model to ONNX format\"\"\"\n",
        "        try:\n",
        "            # Fix model architecture based on type\n",
        "            if 'vgg_net' in str(model_path) or 'mobile_net' in str(model_path):\n",
        "                model = self.fix_transfer_learning_model(model_path)\n",
        "            else:\n",
        "                model = self.fix_sequential_model(model_path)\n",
        "\n",
        "            # Set input and output names\n",
        "            input_signature = (tf.TensorSpec(shape=(None, *self.input_shape),\n",
        "                                          dtype=tf.float32, name=\"input\"),)\n",
        "\n",
        "            model_name = Path(model_path).stem\n",
        "            onnx_path = self.output_dir / f\"{model_name}.onnx\"\n",
        "\n",
        "            model_proto, _ = tf2onnx.convert.from_keras(\n",
        "                model,\n",
        "                input_signature=input_signature,\n",
        "                opset=13,\n",
        "                output_path=str(onnx_path)\n",
        "            )\n",
        "\n",
        "            self.logger.info(f\"Successfully converted model to ONNX: {onnx_path}\")\n",
        "            return onnx_path\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error converting to ONNX: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    # Initialize converter\n",
        "    converter = ModelConverter()\n",
        "\n",
        "    # Setup data generator for quantization\n",
        "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/qidk/processed_dataset/train',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical'\n",
        "    )\n",
        "\n",
        "    # Convert models\n",
        "    model_paths = [\n",
        "        '/content/models/basic_cnn_final.h5',\n",
        "        '/content/models/vgg_net_final.h5',\n",
        "        '/content/models/mobile_net_final.h5'\n",
        "    ]\n",
        "\n",
        "    for model_path in model_paths:\n",
        "        try:\n",
        "            print(f\"\\nProcessing {Path(model_path).stem}\")\n",
        "\n",
        "            # Convert to TFLite\n",
        "            tflite_path = converter.convert_to_tflite(\n",
        "                model_path,\n",
        "                train_generator=train_generator,\n",
        "                quantize=True\n",
        "            )\n",
        "\n",
        "            # Convert to ONNX\n",
        "            onnx_path = converter.convert_to_onnx(model_path)\n",
        "\n",
        "            print(f\"Successfully converted {Path(model_path).stem}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing model {model_path}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKMD6dWUfLls"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
